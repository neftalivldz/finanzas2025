{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ea3907-73aa-4ca2-b430-c6033e6b90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../credentials.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df741dd5-cd85-4a7c-9ed6-bfb06fdbfdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = GOOGLE_KEY\n",
    "HUGGINGFACE_API_KEY = HUGGINGFACE_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "266f661e-1181-4f76-bb26-2d5ad80d6ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47def95526546f7adb98b34a97d8984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50912c1b5a8f4a97943a08443c3a9a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b022bade70744272874b93a5947ca047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239302e363364bd797d3158f6d8fa5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325865a260234cb3b3fbc2f5ca94d578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd925161ccd43cfb6d9a50ea7a44f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1611753dcaf94112a2c5ab848743cf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3084b0830b84d8db1e17aa5764eac38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1c91ffbece4cdb84fa3b29803e848d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050e4af71ff94c20af4f34c8fb1c7d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5d84f0728843938f7eeb563497ffb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import streamlit as st\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from litellm import completion\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from dotenv import load_dotenv\n",
    " \n",
    "load_dotenv()\n",
    "gemini_api_key = GOOGLE_KEY\n",
    "huggingface_token = HUGGINGFACE_KEY\n",
    " \n",
    "#if huggingface_token:\n",
    "#    login(token=huggingface_token)\n",
    "    \n",
    "client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "text_embedding_model = SentenceTransformer('all-MiniLM-L6-v2', token=huggingface_token)\n",
    "arxiv_tool = ArxivQueryRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e160b0-4b6e-4bae-b10b-038c92cdd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(uploaded_files):\n",
    "    all_text = \"\"\n",
    "    for uploaded_file in uploaded_files:\n",
    "        reader = PyPDF2.PdfReader(uploaded_file)\n",
    "        for page in reader.pages:\n",
    "            all_text += page.extract_text() or \"\"\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1ecb532-522b-48c7-a309-bed23fc48af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_and_store(all_text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=50, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.split_text(all_text)\n",
    "    try:\n",
    "        client.delete_collection(name=\"knowledge_base\")\n",
    "    except Exception:\n",
    "        pass\n",
    " \n",
    "    collection = client.create_collection(name=\"knowledge_base\")\n",
    " \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        embedding = text_embedding_model.encode(chunk)\n",
    "        collection.add(\n",
    "            ids=[f\"chunk_{i}\"],\n",
    "            embeddings=[embedding.tolist()],\n",
    "            metadatas=[{\"source\": \"pdf\", \"chunk_id\": i}],\n",
    "            documents=[chunk]\n",
    "        )\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3694359-d6c7-4c28-8868-45ca159ad389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, collection, top_k=2):\n",
    "    query_embedding = text_embedding_model.encode(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()], n_results=top_k\n",
    "    )\n",
    "    return results\n",
    " \n",
    "def generate_response(query, context):\n",
    "    prompt = f\"Query: {query}\\nContext: {context}\\nAnswer:\"\n",
    "    response = completion(\n",
    "        model=\"gemini/gemini-1.5-flash\",\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        api_key=gemini_api_key\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e1b45fb-9db0-4bae-891a-0080aa27a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title(\"RAG-powered Financial Analyst Assistant\")\n",
    " \n",
    "    # Option to choose between PDF upload and arXiv search\n",
    "    option = st.radio(\"Choose an option:\", (\"Upload PDFs\", \"Search pdf Bank\"))\n",
    " \n",
    "    if option == \"Upload PDFs\":\n",
    "        uploaded_files = st.file_uploader(\"Upload PDF files\", accept_multiple_files=True, type=[\"pdf\"])\n",
    "        if uploaded_files:\n",
    "            st.write(\"Processing uploaded files...\")\n",
    "            all_text = extract_text_from_pdfs(uploaded_files)\n",
    "            collection = process_text_and_store(all_text)\n",
    "            st.success(\"PDF content processed and stored successfully!\")\n",
    " \n",
    "            query = st.text_input(\"Enter your query:\")\n",
    "            if st.button(\"Execute Query\") and query:\n",
    "                results = semantic_search(query, collection)\n",
    "                context = \"\\n\".join(results['documents'][0])\n",
    "                response = generate_response(query, context)\n",
    "                st.subheader(\"Generated Response:\")\n",
    "                st.write(response)\n",
    " \n",
    "    elif option == \"Search pdf\":\n",
    "        query = st.text_input(\"Enter your search query for arXiv:\")\n",
    " \n",
    "        if st.button(\"Search ArXiv\") and query:\n",
    "            arxiv_results = arxiv_tool.invoke(query)\n",
    "            st.session_state[\"arxiv_results\"] = arxiv_results  \n",
    "            st.subheader(\"Search Results:\")\n",
    "            st.write(arxiv_results)\n",
    " \n",
    "            collection = process_text_and_store(arxiv_results)\n",
    "            st.session_state[\"collection\"] = collection  \n",
    " \n",
    "            st.success(\"arXiv paper content processed and stored successfully!\")\n",
    " \n",
    "        # Only allow querying if search has been performed\n",
    "        if \"arxiv_results\" in st.session_state and \"collection\" in st.session_state:\n",
    "            query = st.text_input(\"Ask a question about the paper:\")\n",
    "            if st.button(\"Execute Query on Paper\") and query:\n",
    "                results = semantic_search(query, st.session_state[\"collection\"])\n",
    "                context = \"\\n\".join(results['documents'][0])\n",
    "                response = generate_response(query, context)\n",
    "                st.subheader(\"Generated Response:\")\n",
    "                st.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e3fe71-ea52-4674-b016-057a62d066f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3737097518.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstreamlit run app.py\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9b3cc-db67-400c-a218-349506538770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
